# 103.2 Process text streams using filters

1. Someone just donated a laptop to your school and now you wish to install Linux on it. There is
no manual and you were forced to boot it from a USB thumb drive with no graphics
whatsoever. You do get a shell terminal and you know, for every processor you have there will
be a line for it in the /proc/cpuinfo file:
processor : 0
vendor_id : GenuineIntel
cpu family : 6
model : 158
(lines skipped)
processor : 1
vendor_id : GenuineIntel
cpu family : 6
model : 158
(more lines skipped)
◦ Using the commands grep and wc display how many processors you have.
Here are two options:
$ cat /proc/cpuinfo | grep processor | wc -l
$ grep processor /proc/cpuinfo | wc -l
Now that you know there are several ways you can do the same thing, when should you be
using one or the other? It really depends on several factors, the two most important ones
being performance and readability. Most of the time you will use shell commands inside
shell scripts to automate your tasks and the larger and more complex your scripts become
the more you need to worry about keeping them fast.
◦ Do the same thing with sed instead of grep
Now, instead of grep we will try this with sed:
$ sed -n /processor/p /proc/cpuinfo | wc -l
Here we used sed with the -n parameter so sed will not print anything except for what
matches with the expression processor, as instructed by the p command. As we did in the
grep solutions, wc -l will count the number of lines, thus the number of processors we
have.
Study this next example:
$ sed -n /processor/p /proc/cpuinfo | sed -n '$='
This command sequence provides identical results to the previous example where the
output of sed was piped into a wc command. The difference here is that instead of using wc
-l to count the number of lines, sed is again invoked to provide equivalent functionality.
Once more, we are suppressing the output of sed with with the -n option, except for the
expression that we are explicitly calling, which is '$='. This expression tells sed to match
the last line ($) and then to print that line number (=).
2. Explore your local /etc/passwd file with the grep, sed, head and tail commands per the
tasks below:
◦ Which users have access to a Bash shell?
$ grep ":/bin/bash$" /etc/passwd
We will improve this answer by only displaying the name of the user that utilizes the Bash
shell.
$ grep ":/bin/bash$" /etc/passwd | cut -d: -f1
The user name is the first field (-f1 parameter of the cut command) and the /etc/passwd
file uses : as separators (-d: parameter of the cut command) we just pipe the output of the
grep command to the appropriate cut command.
◦ Your system has various users that exists to handle specific programs or for administrative
purposes. They do not have access to a shell. How many of those exist in your system?
The easiest way to find this is by printing out the lines for accounts that do not use the Bash
shell:
$ grep -v ":/bin/bash$" /etc/passwd | wc -l
How many users and groups exist in your system (remember: use only the /etc/passwd
file)
The first field of any given line in your /etc/passwd file is the user name, the second is
typically an x indicating the user password is not stored here (it is encrypted in the
/etc/shadow file). The third is the user id (UID) and the fourth is the group id (GID). So this
should give us the number of users:
$ cut -d: -f3 /etc/passwd | wc -l
Well, most of the time it will. However, there are situations where you will set different
super users or other special kinds of users sharing the same UID (user id). So, to be on the
safe side we will pipe the result of our cut command to the sort command and then count
the number of lines.
$ cut -d: -f3 /etc/passwd | sort -u | wc -l
Now, for the number of groups:
$ cut -d: -f4 /etc/passwd | sort -u | wc -l
◦ List only the first line, the last line and the tenth line of your /etc/passwd file
This will do:
$ sed -n -e '1'p -e '10'p -e '$'p /etc/passwd
Remember that the parameter -n tells sed not to print anything other than what is specified
by the p command. The dollar sign ($) used here is a regular expression meaning the last
line of the file.
3. Consider this /etc/passwd file example. Copy the lines below to a local file named mypasswd
for this exercise.
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
nvidia-persistenced:x:121:128:NVIDIA Persistence Daemon,,,:/nonexistent:/sbin/nologin
libvirt-qemu:x:64055:130:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
libvirt-dnsmasq:x:122:133:Libvirt Dnsmasq,,,:/var/lib/libvirt/dnsmasq:/usr/sbin/nologin
carol:x:1000:2000:Carol Smith,Finance,,,Main Office:/home/carol:/bin/bash
dave:x:1001:1000:Dave Edwards,Finance,,,Main Office:/home/dave:/bin/ksh
emma:x:1002:1000:Emma Jones,Finance,,,Main Office:/home/emma:/bin/bash
frank:x:1003:1000:Frank Cassidy,Finance,,,Main Office:/home/frank:/bin/bash
grace:x:1004:1000:Grace Kearns,Engineering,,,Main Office:/home/grace:/bin/ksh
henry:x:1005:1000:Henry Adams,Sales,,,Main Office:/home/henry:/bin/bash
john:x:1006:1000:John Chapel,Sales,,,Main Office:/home/john:/bin/bash
◦ List all users in group 1000 (use sed to select only the appropriate field) from your
mypasswd file:
The GID is the fourth field in the /etc/passwd file. You might be tempted to try this:
$ sed -n /1000/p mypasswd
In this case you will also get this line:
carol:x:1000:2000:Carol Smith,Finance,,,Main Office:/home/carol:/bin/bash
You know this is not correct since Carol Smith is a member of GID 2000 and the the match
occurred because of the UID. However, you may have noticed that after the GID the next
field starts with an upper case character. We can use a regular expression to solve this
problem.
$ sed -n /:1000:[A-Z]/p mypasswd
The expression [A-Z] will match any single upper case character. You will learn more about
this in the respective lesson.
◦ List only the full names of all the users for this group (use sed and cut):
Use the same technique you used to solve the first part of this exercise and pipe it to a cut
command.
$ sed -n /:1000:[A-Z]/p mypasswd | cut -d: -f5
Dave Edwards,Finance,,,Main Office
Emma Jones,Finance,,,Main Office
Frank Cassidy,Finance,,,Main Office
Grace Kearns,Engineering,,,Main Office
Henry Adams,Sales,,,Main Office
John Chapel,Sales,,,Main Office
Not quite there! Do note how the fields inside your results can be separated by ,. So we will
pipe the output to another cut command, using the , as a delimiter.
$ sed -n /:1000:[A-Z]/p mypasswd | cut -d: -f5 | cut -d, -f1
Dave Edwards
Emma Jones
Frank Cassidy
Grace Kearns
Henry Adams
John Chapel

1. Once more using the mypasswd file from the previous exercises, devise a Bash command that
will select one individual from the Main Office to win a raffle contest. Use the sed command to
only print out the lines for the Main Office, and then a cut command sequence to retrieve the
first name of each user from these lines. Next you will want to randomly sort these names and
only print out the top name from the list.
First explore how the parameter -R manipulates the output of the sort command. Repeat this
command a couple times on your machine (note you will need to enclose 'Main Office' within
single quotes, so sed will handle it as a single string):
$ sed -n /'Main Office'/p mypasswd | cut -d: -f5 | cut -d, -f1 | sort -R
Here is a solution to the problem:
$ sed -n /'Main Office'/p mypasswd | cut -d: -f5 | cut -d, -f1 | sort -R | head -1
2. How many people work in Finance, Engineering and Sales? (Consider exploring the uniq
command.)
Keep building on top of what you learned from the previous exercises. Try the following:
$ sed -n /'Main Office'/p mypasswd
$ sed -n /'Main Office'/p mypasswd | cut -d, -f2
Notice now we do not care about the : as a delimiter. We just want the second field when we
split the lines by the , characters.
$ sed -n /'Main Office'/p mypasswd | cut -d, -f2 | uniq -c
4 Finance
1 Engineering
2 Sales
The uniq command will only output the unique lines (not the repeating lines) and the
parameter -c tells uniq to count the occurences of the equal lines. There is a caveat here: uniq
will only consider adjacent lines. When this is not the case you will have to use the sort
command.
Now you want to prepare a CSV (comma separated values) file so you can easily import, from
the mypasswd file in the previous example, the file names.csv into LibreOffice. The file
contents will have the following format:
First Name,Last Name,Position
Carol,Smith,Finance
...
John,Chapel,Sales
Tip: Use the sed, cut, and paste commands to achieve the desired results. Note that the
comma (,) will be the delimiter for this file.
Start with the sed and cut commands, building on top of what we learned from the previous
exercises:
$ sed -n /'Main Office'/p mypasswd | cut -d: -f5 | cut -d" " -f1 > firstname
Now we have the file firstname with the first names of our employees.
$ sed -n /'Main Office'/p mypasswd | cut -d: -f5 | cut -d" " -f2 | cut -d, -f1 > lastname
Now we have the file lastname containing the surnames of each employee.
Next we determine which department each employee works in:
$ sed -n /'Main Office'/p mypasswd | cut -d: -f5 | cut -d, -f2 > department
Before we work on the final solution, try the following commands to see what type of output
they generate:
$ cat firstname lastname department
$ paste firstname lastname department
And now for the final solution:
$ paste firstname lastname department | tr '\t' ,
$ paste firstname lastname department | tr '\t' , > names.csv
Here we use the command tr to translate \t, the tab separator, by a ,. tr is quite useful when
we need to exchange one character for another. Be sure to review the man pages for both tr
and paste. For example, we can use the -d option for the delimiter to make the previous
command less complex:
$ paste -d, firstname lastname department
We used the paste command here once we needed to get you familiar with it. However we
could have easily performed all of the tasks in a single command chain:
$ sed -n /'Main Office'/p mypasswd | cut -d: -f5 | cut -d, -f1,2 | tr ' ' , > names.csv
4. Suppose that the names.csv spreadsheet created in the previous exercise is an important file
and we want to make sure nobody will tamper with it from the moment we send it to someone
and the moment our recipient receives it. How can we insure the integrity of this file using
md5sum?
If you look into the man pages for md5sum, sha256sum and sha512sum you will see they all
start with the following text:
“compute and check XXX message digest”
Where “XXX” is the algoritm that will be used to create this message digest.
We will use md5sum as an example and later you can try with the other commands.
$ md5sum names.csv
61f0251fcab61d9575b1d0cbf0195e25 names.csv
Now, for instance, you can make the file available through a secure ftp service and send the
generated message digest using another secure means of communication. If the file has been
slightly modified the message digest will be completely different. Just to prove it, edit
names.csv and change Jones to James as demonstrated here:
$ sed -i.backup s/Jones/James/ names.csv
$ md5sum names.csv
f44a0d68cb480466099021bf6d6d2e65 names.csv
Whenever you make files available for download, it is always a good practice to also distribute
a message digest correspondent so people who download your file can produce a new message
digest and check against the original. If you browse through https://kernel.org you will find the
page https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/sha256sums.asc where you can
obtain the sha256sum for all files available for download.
5. You promised yourself that you would read a classic book 100 lines per day and you decided to
start with Mariner and Mystic by Herman Melville. Devise a command using split that will
separate this book into sections of 100 lines each. In order to get the book in plain text format,
search for it at https://www.gutenberg.org.
First we will get the whole book from the Project Gutenberg site, where you can get this and
other books that are available in the public domain.
$ wget https://www.gutenberg.org/files/50461/50461-0.txt
You might need to install wget if it is not already installed in your system. Alternatively, you
can also use curl. Use less to verify the book:
$ less 50461-0.txt
Now we will split the book into chunks of 100 lines each:
$ split -l 100 -d 50461-0.txt melville
50461-0.txt is the file we will be splitting. melville will be the prefix for the split files. The
-l 100 specifies the number of lines and the -d option tells split to number the files (using
the provided suffix). You can use nl on any of the splitted files (probably not on the last one)
and confirm each one of them have 100 lines.
6. Using ls -l on the /etc directory, what kind of listing do you get? Using the cut command on
the output of the given ls command how would you display only the file names? What about
the filename and the owner of the files? Along with the ls -l and cut commands, utilize the
tr command to squeeze multiple occurrences of a space into a single space to aid in formatting
the output with a cut command.
The ls command by itself will give you just the names of the files. We can, however, prepare
the output of the ls -l (the long listing) to extract more specific information.
$ ls -l /etc | tr -s ' ' ,
drwxr-xr-x,3,root,root,4096,out,24,16:58,acpi
-rw-r--r--,1,root,root,3028,dez,17,2018,adduser.conf
-rw-r--r--,1,root,root,10,out,2,17:38,adjtime
drwxr-xr-x,2,root,root,12288,out,31,09:40,alternatives
-rw-r--r--,1,root,root,401,mai,29,2017,anacrontab
-rw-r--r--,1,root,root,433,out,1,2017,apg.conf
drwxr-xr-x,6,root,root,4096,dez,17,2018,apm
drwxr-xr-x,3,root,root,4096,out,24,16:58,apparmor
drwxr-xr-x,9,root,root,4096,nov,6,20:20,apparmor.d
The -s parameter instructs tr to shrink the repeated spaces into a single instance of a space.
The tr command works for any kind of repeating character you specify. Then we replace the
spaces with a comma ,. We actually do not need to replace the spaces in our example so we
will just omit the ,.
$ ls -l /etc | tr -s ' '
drwxr-xr-x 3 root root 4096 out 24 16:58 acpi
-rw-r--r-- 1 root root 3028 dez 17 2018 adduser.conf
-rw-r--r-- 1 root root 10 out 2 17:38 adjtime
drwxr-xr-x 2 root root 12288 out 31 09:40 alternatives
-rw-r--r-- 1 root root 401 mai 29 2017 anacrontab
-rw-r--r-- 1 root root 433 out 1 2017 apg.conf
drwxr-xr-x 6 root root 4096 dez 17 2018 apm
drwxr-xr-x 3 root root 4096 out 24 16:58 apparmor
If I want just the filenames then all that we need displayed is the ninth field:
$ ls -l /etc | tr -s ' ' | cut -d" " -f9
For the filename and the owner of a file we will need the ninth and the third fields:
$ ls -l /etc | tr -s ' ' | cut -d" " -f9,3
What if we just need the folder names and its owner?
$ ls -l /etc | grep ^d | tr -s ' ' | cut -d" " -f9,3
7. This exercise assumes you are on a real machine (not a virtual machine). You must also have a
USB stick with you. Review the manual pages for the tail command and find out how to follow a file as text is appended to it. While monitoring the output of a tail command on the
/var/log/syslog file, insert a USB stick. Write out the full command that you would use to get
the Product, Manufacturer and the total amount of memory of your USB stick.
$ tail -f /var/log/syslog | grep -i 'product\:\|blocks\|manufacturer'
Nov 8 06:01:35 brod-avell kernel: [124954.369361] usb 1-4.3: Product: Cruzer Blade
Nov 8 06:01:35 brod-avell kernel: [124954.369364] usb 1-4.3: Manufacturer: SanDisk
Nov 8 06:01:37 brod-avell kernel: [124955.419267] sd 2:0:0:0: [sdc] 61056064 512-byte
logical blocks: (31.3 GB/29.1 GiB)
Of course this is an example and the results may vary depending on your USB memory stick
manufacturer. Notice now we use the -i parameter with the grep command as we are not sure
if the strings we are searching for were in upper or lower case. We also used the | as a logical
OR so we search for lines containing product OR blocks OR manufacturer.